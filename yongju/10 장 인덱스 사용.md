# 10장 인덱스 사용

<br/>

**들어가기.**

- 테이블의 데이터는 순서 없이 쌓이게 되므로 특정 조건의 데이터를 찾으려면 테이블의 모든 데이터에 접근하여 비교하는 과정이 필요합니다. 그러나 인덱스가 있는 경우 검색키가 정렬되어 있기 때문에 조건 검색 시 속도가 빠릅니다.
- 인덱스를 생성하면 특정 컬럼(속성)의 값을 기준으로 정렬해 데이터의 물리적 위치 주소도 함께 별도 파일에 저장합니다. 이 때 특정 컬럼을 search-key라하며 실제 데이터의 물리적 위치 값을 pointer라 합니다. 보통 인덱스는 테이블 크기의 10% 정도의 저장 공간을 차지합니다.
- 인덱스를 사용할 컬럼을 정하는 방법
    - 인덱스는 where 절에서 ‘자주 조회’하고 ‘수정 빈도’가 낮고 ‘데이터 중복’이 적은 컬럼을 선택하는것이 좋습니다. join 조건으로 자주 사용되는 컬럼도 인덱스로 사용하면 좋습니다. (테이블에 인덱스가 너무 많으면 데이터 수정 시 소요 시간이 커집니다)

<br/><br/>

# 1. 인덱스와 B+tree

<br/>

## (1) B+tree 인덱스

- 이름 그대로 데이터를 트리 구조로 저장하는 형태의 인덱스 입니다. 가장 많이 사용되며 데이터베이스에서 인덱스라고 하면 거의 B+tree를 의미합니다. RDB에서 create index 실행시 B+tree가 만들어 집니다. B+tree는 트리의 리프 노드에만 키 값을 저장하는 알고리즘으로 B-tree에 비해 검색을 보다 효율적으로 개선한 알고리즘 입니다. 데이터베이스 외에 파일 시스템 등에서도 사용됩니다.

![사진1](https://github.com/KimYongJ/SQL-level-up/assets/106525587/42f1902c-9775-4bfa-904e-1bd763b03659)

- **B+tree가 뛰어난 이유**
    - B+tree는 루트와 리프의 거리를 가능한 일정하게 유지하려 합니다. 따라서 균형이 잘 잡혀 검색 성능이 안정적입니다. 키값 사이에 검색 속도의 불균형이 거의 없어 데이터양이 증가해도 검색 속도가 갑자기 악화하는 일이 없고 등호(=), 부등호(>,<)를 사용한 검색에도 사용 가능합니다.
    - 트리의 깊이도 대개 3-4 정도의 수준으로 일정하며 데이터가 정렬된 상태를 유지하므로 이분 탐색을 통해 검색 비용을 크게 줄일 수 있습니다. 이미 정렬되어 있으므로 집약 함수 등에서 요구되는 정렬을 하지 않은 채 실행될 수도 있어 성능상 이점이 있습니다.

<br/>

## (2) 기타 인덱스

- **비트맵 인덱스**
    - 데이터를 비트 플래그로 변환해서 저장하는 형태의 인덱스로, 카디널리티가 낮은 필드에 대해 효과를 발휘합니다. 갱신시 오버헤드가 크다는 단점이 있습니다.
- **해시 인덱스**
    - 키를 해시 분산해서 등가 검색을 고속으로 실행하고자 만들어진 인덱스 입니다. 거의 사용되지 않는 인덱스 입니다.

<br/>

## (3) 인덱스 활용시 알아야 할 것

- **카디널리티와 선택률**
    - **카디널리티 :** **값의 균형**을 나타내는 개념으로 **카디널리티가 가장 높은 필드** 는 모든 레코드(행)에 다른 값이 들어가 있는 유일 키 필드(컬럼=열)입니다. 반대로 모든 레코드에 같은 값이 들어가 있다면 카디널리티가 낮은 필드 입니다.
    
    ![사진2](https://github.com/KimYongJ/SQL-level-up/assets/106525587/dc7734e3-37c5-4049-bb2d-f62eba279945)


    
    - **선택률 :** 특정 필드 값을 지정했을 때 테이블 전체에서 몇 개의 레코드가 선택 되는지를 나타내는 개념입니다. 100개의 레코드를 가진 테이블에서 유일 키로( pkey = 1 ) 등호를 지정해 한 개의 레코드를 선택한다면, 1/100  = 0.01로 선택률은 1%입니다.
- **클러스터링 팩터**
    - 클러스터링 팩터는 저장소에 같은 값이 어느 정도 물리적으로 뭉쳐 존재하는 지를 나타내는 지표로 높을수록 물리적으로 데이터가 분산되어 있고, 낮을 수록 뭉쳐있다는 뜻입니다. 인덱스로 접근할 때는 특정 값에만 접근하는 경우가 많으므로 보통 클러스터링 팩터가 낮을 수록 접근할 데이터양이 적어져 좋습니다. (데이터의 물리적 위치는 구현에 의존합니다.)
- **인덱스를 사용하는 조건**
    - **조건 1 :** 카디널리티가 높은 것, 즉 값이 평균치에서 많이 흩어져 있을수록 좋은 인덱스 후보입니다.
    - **조건 2 :** 선택률이 낮을 것, 즉 한 번의 선택으로 레코드가 조금만 선택되는 것이 좋은 후보입니다. (보통 5% 이하) 즉 특정 필드 값을 지정(=) 했을 때 100개 중 5개 정도 선택된다면 인덱스를 사용하는 것이 나을 수 있다는 뜻입니다.

<br/><br/>

# 2. 인덱스로 성능 향상이 어려운 경우

- 인덱스를 정하는 일은 테이블 정의와 SQL만 보고 할 수 있는 작업이 아닙니다.(프론트 단에서 어떤 조회조건을 입력 받을지에 따라 달라지기 때문)
- 적절한 인덱스 장성 법
    - SQL의 검색 조건과 결합 조건을 바탕으로 데이터를 효율적으로 압축할 수 있게 조건을 찾아야 합니다. 이 조건을 찾기 위해서는 SQL 구문과 검색 키 필드의 카디널리티를 알아야 합니다.

<br/>

## (1)  데이터 압축 조건이 해당 SQL 구문에 존재하지 않을 때 예시

```jsx
[ 테이블 예시 ]
create table Orders(				    -- // 주문 테이블
order_id char(8) not null,			-- // 주문 ID
shop_id char(4) not null,			  -- // 주문 받은 매장
shop_name varchar(256) not null,-- // 주문받은 매장 이름
receive_date date not null,			-- // 주문 날짜
process_flg char(1) not null,		-- // 처리 플래그
constraint pk_Orders PRIMARY KEY(order_id)
);
```

### 예시 1) 레코드를 제대로 압축하지 못하는 경우

```jsx
[ 쿼리 예시 ]
select order_id, receive_date
from Orders
where process_flg = '5'; -- // 주문단계(1), 주문완료(2), 재고확인중(3), 배송준비중(4), 배송완료(5)

[ 데이터 예시 ]
process_flg = 1 은 데이터가 200만 건
process_flg = 2 은 데이터가 500만 건
process_flg = 3 은 데이터가 500만 건
process_flg = 4 은 데이터가 500만 건
process_flg = 5 은 데이터가 8,300만 건
```

- where 조건에 있는 process_flg로 인덱스를 만든다고 가정했을 때 플래그에 5를 대입할 때 조회시 인덱스를 통해 찾는다면 테이블 풀 스캔을 할 때보다 느려질 가능성이 큽니다. 플래그 값이 5인 것의 데이터는 8,300만건으로 전체 데이터의 83%나 됩니다. 이는 선택률이 83%라는 말과 같습니다. **인덱스가 제대로 작동하기 위해서는 레코드를 크게 압축할 수 있는 검색 조건이 있어야 합니다**.

### 예시 2) 입력 매개변수에 따라 선택률이 변동하는 경우

```jsx
[ 쿼리 예시 ]
select order_id
from Orders
where receive_date between {param1} and {param2}
```

- 위 쿼리에서 보면 receive_date 컬럼은 날짜를 저장하고 있는 컬럼이고  param1과 2는 각각 매개변수로 전달되는 데이터 입니다. 위 쿼리에서는 select 하고자 하는 기간이( 즉, param1과 2가 ) 1년 일수도 있고, 10년 일수도 있고, 일주일 일수도 있습니다. 매개 변수에 따라 데이터 선택률이 달라지기 때문에 해당 컬럼을 인덱스로 만들기에 적절하지 않습니다.

### 예시 3) LIKE 연산자를 사용해 인덱스를 생성하는 경우

```jsx
[ 쿼리 예시 ]
select order_id
from Orders
where shop_name LIKE '%신촌%'
```

- 위 쿼리를 보면 shop_name 컬럼을 LIKE 연산으로 범위를 한정하고 있습니다. LKE연산으로 데이터를 많이 줄인다고 해도 위 쿼리는 인덱스를 생성할 수 없습니다. '%신촌%'은 안되지만 ‘%신촌’은 인덱스를 생성할 수 있습니다. 이유는 인덱스 생성 문법이 그것을 제한하고 있습니다. 인덱스로 사용되는 컬럼을 연산하는것은 불가합니다.
- **인덱스 필드로 연산하는 경우에는 인덱스 스캔이 불가합니다.**
    - 위 예시에서 shop_name LIKE ‘신촌%’ 은 인덱스 스캔이 가능하지만 '%신촌%' 방식의 중간 연산은 불가합니다. 아래는 여러 예시 입니다.
    
    ```jsx
    [ 불가 문법 ]
    SELECT *
    FROM EXAMPLE
    WHERE col * 1.1 > 100;
    [ 가능 문법 ]
    SELECT *
    FROM EXAMPLE
    WHERE col > 100/1.1;
    
    [ 설명 ]
    col 자체를 연산해버리면 인덱스 스캔이 되지 않습니다. 인덱스 내부에 존재하는 값은 
    어디까지나 col이지, col*1.1을 연산한 값이 아니기 때문입니다.
    ```
    
    ```jsx
    [ 불가 문법 ]
    SELECT *
    FROM EXAMPLE
    WHERE COL IS NULL
    
    [ 설명 ]
    IS NULL을 사용하는 경우에도 인덱스를 사용할 수 없습니다. 그 이유는 인덱스 내부에 
    NULL 자체가 없기 때문입니다. COL의 값이 NULL이면, 인덱스 테이블에서 NULL을 찾을 순
    없어요
    ```
    
    ```jsx
    [ 불가 문법 ]
    SELECT *
    FROM EXAMPLE
    WHERE LENGTH(COL) = 10;
    
    [ 설명 ]
    COL을 인덱스로 지정했다고 해도 위 문법에서는 인덱스 스캔이 발생하지 않습니다. 다른 이유와
    마찬가지로 인덱스 내부에 존재하는 값은 어디까지나 COL이지, LENGTH(COL)이 아니기 때문 입니다.
    ```
    
<br/><br/>

# 3. 인덱스를 사용할 수 없는 경우 대처법

<br/>

## (1) 애플리케이션의 설정으로 처리하는 방법

- **외부 설정에 의한 처리 :** 2.에서 살펴본 Orders 테이블에서 주문 받은 매장 ID로만 검색했을 때 데이터 압축이 힘듭니다. 이를 보완하기 위해 검색할 때 매장 ID와 함께 주문 날짜도 동시에 입력해야 검색이 가능토록 UI를 바꿔(압축률을 높여) 처리 할 수 있습니다. 또한, 기간 검색시 범위를 최초 무제한에서 최대 1개월 혹은 1년으로 범위를 줄인다면 인덱스를 사용할 가능성이 생깁니다.
- **데이터 마트에 의한 처리 :** 데이터 마트는 특정한 쿼리(군)에서 필요한 데이터만을 저장하는, 상대적으로 작은 크기의 테이블을 의미합니다. 원래 테이블의 부분 집합(서브셋)이라고 보면 됩니다. 접근 대상 테이블의 크기를 작게 해서 I/O의 양을 줄이는 것이 데이터 마트의 목적입니다. 위에서 살펴본 Orders 테이블에서 order_id(주문 테이블 PK)와 receive_date(주문 날짜)만을 조회하는 쿼리가 있다면 2개의 컬럼 정보만 저장하는 테이블을 따로 만들어(복사본으로) 관리하는 것입니다.
- **데이터 마트에 의한 처리 주의점 4가지**
    - **데이터 신선도 :** 테이터 마트는 본 테이블의 부분적 복사본입니다. 따라서 특정한 시점마다 원본 테이블에서 데이터를 동기화해야 합니다. 이 동기 사이클이 짧아야 데이터 신선도가 높아지며 원본 테이블과 비슷한 모습을 갖습니다. 데이터 신선도가 중요한 경우라면 이러한 경우를 잘 고려해야 합니다.
    - **데이터 마트 크기 :** 데이터 마트의 목적은 I/O를 작게하는 것입니다. 그러나 SELECT * 처럼 모든 필드를 검색하거나, 검색 조건의 선택률이 높아 데이터 압축을 하지 못할 경우 데이터 마트를 만들어도 성능 개선은 불가합니다. 다만 **GROUP BY 절을 미리 사용해 집계를 마친 데이터마트를 만들어 두면 효과적인 성능을 기대할 수 있습니다.**
    - **데이터 마트 수 :** 데이터 마트 수가 많아지면 저장소 용량을 차지하고, 백업과 스냅샷을 할 때의 시간이 오래 걸리는 문제가 생깁니다. 따라서 데이터 마트에 지나치게 의존하는 것은 좋지 못합니다.
    - **배치 윈도우 :** 데이터 마트를 만드는데 시간이 걸리므로 배치 윈도우에 부하를 줍니다. 만들어진 데이터 마트는 어느 정도 규모의 갱신이 발생할 때 통계 정보도 다시 수집해야 합니다. 그렇기에 이런 처리를 원할하게 할 배치 윈도우와 Job Net을 고려해야 합니다.

<br/>

## (2) 인덱스 온리 스캔

- 인덱스 온리 스캔은 SQL 구문이 접근하려는 대상 I/O의 감소를 목적으로 하는 점에서 데이터 마트와 같습니다. 특히 데이터 마트에서 동기 문제를 해결할 수 있는 방법 입니다. **인덱스 온리 스캔은 이름처럼 인덱스를 사용한 고속화 방법이며 테이블 풀 스캔을 할 때 검사 대상을 테이블이 아닌 인덱스로 바꿀 수 있습니다.**
    
    ```jsx
    [ 커버링 인덱스 작성 예시 ]
    CREATE INDEX CoveringIndex ON Orders (order_id, receive_date);
    
    [ 조회 예시 ]
    SELECT order_id,receive_date FROM Orders;
    ```
    
    - [ 조회 예시 ] 처럼 컬럼 2개를 SELECT하는 쿼리가 있을 때 위와 같이 커버링 인덱스를 작성했다면 테이블이 아닌 인덱스만을 스캔 대상으로 하는 검색(인덱스 온리 스캔)을 사용할 수 있게 됩니다.( 커버링 인덱스를 작성하지 않으면 테이블 풀스캔)
- **인덱스 온리 스캔은 SQL 구문에서 필요한 필드를 인덱스만으로 커버할 수 있는 경우에 테이블 접근을 생략하는 기술 입니다. 인덱스는 테이블 필드의 부분 집합만 저장하므로 원래 테이블에 비해 크기가 굉장히 작습니다.** 뿐만 아니라 데이터 마트 사용시 애플리케이션도 수정하나 인덱스를 사용할 경우엔 그럴 필요가 없습니다.
- **인덱스 온리 스캔과 컬럼 지향 데이터베이스**
    - 위에서 말한 **인덱스 온리 스캔은 특정 상황에서 검색 성능을 극단적으로 높일 수 있는 강력한 기능입니다.** 이는 로우(row) 지향 데이터베이스를 컬럼(column)지향 데이터베이스로 구현한 것입니다. 로우(row) 지향 데이터베이스는 쉽게 말해 레코드(한 행) 단위로 데이터를 저장하는 형태입니다. 이런 로우 지향 데이터베이스는 하나의 컬럼만 조회 할 때 낭비가 일어납니다.(I/O가 레코드 단위로 일어나 불필요한 컬럼도 읽어야함) 하지만 컬럼 지향 데이터베이스는 이름 그대로 데이터의 저장 단위를 필드로 바꾸어 불필요한 필드를 읽지 않도록 만든 방법 입니다.
    
- **인덱스 온리 스캔 주의점**
    - 1) 한 개의 인덱스에 포함할 수 있는 필드 수에 제한이 있습니다. 또한 인덱스의 크기가 너무 커지면 물리 I/O를 줄인다는 최초 목적이 희미해집니다.
    - 2) 갱신 오버 헤드가 커집니다. 인덱스 온리 스캔을 위한 커버링 인덱스를 만들 상황이라면 필연적으로 필드 수가 많을 겁니다. 따라서 테이블을 갱신할 때의 오버 헤드도 일반적인 인덱스에 비해 큰 경향이 있습니다. 검색 성능 향상 대신 갱신 성능 하향이라는 트레이드 오프가 발생합니다.
    - 3) 정기적인 인덱스 리빌드가 필요합니다. 일반적인 인덱스보다도 인덱스 온리 스캔은 성능이 인덱스 크기에 민감하게 반응 합니다. 때문에 데이터 운용에 인덱스 크기 모니터링과 리빌드를 포함해야 합니다.
    - 4) SQL 구문에 새로운 필드가 추가된다면 사용할 수 없습니다. 커버링 인덱스로 작성한 컬럼 이외의 컬럼을 조회한다면 커버링 인덱스는 더 이상 사용할 수 없게 됩니다.
